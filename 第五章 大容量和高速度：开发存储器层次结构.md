## 大容量和高速度：开发存储器层次结构

### 引言

局部性原理：

- 时间局部性：如果某项数据被访问，那么在不久的将来它可能再次被访问。
- 空间局部性：如果某个数据项被访问，那么与它地址相邻的数据项可能很快也将会被访问

利用局部性原理将计算机存储器组织成为**存储器层次结构**：一种由多存储器层次组成的结构，存储器的容量和访问时间随着离处理器距离增加而增加（金字塔结构）

- 块（block）或行：可存在于或不存在于cache中的信息的最小单元
- 命中率：在高层存储器中找到目标数据的存储访问比例
- 缺失率：~命中率
- 命中时间：访问某存储器层次结构所需要的时间，包括了判断当前访问是命中还是缺失所需要的时间
- 缺失代价：将相应的块从低层存储器替换到高层存储器所需要的时间，包括访问块、将数据逐层传输、将数据插入发生缺失的层和将信息块传递给请求者的时间

---------

### 存储器技术

1. 主存储器由DRAM（动态随机存取存储器）实现
2. 靠近处理器的那层（cache）由SRAM（静态）实现
3. 闪存，这种非易失存储器用作个人移动设备中的二级存储器
4. 磁盘，是服务器中容量最大速度最慢的一层。

#### SRAM技术

不需要刷新，访问时间与周期时间相近，一个基本存储单元由6-8个集体管组成。

当今的处理器芯片集成了多层次的cache，独立的SRAM芯片几乎消失了。

#### DRAM技术

存储单元使用电容保存电荷的方式来存储数据，使用一个晶体管对该电容进行访问。

在电容上保存电荷，不能长久的保持数据，从而必须周期性的刷新。

DRAM采用了两级译码结构，可以通过在一个读周期后紧跟一个写周期的方式一次刷新一整行。

#### 闪存

一种电可擦除的可编程只读存储器

#### 磁盘存储器

- 磁道：位于磁盘表面的数万个同心圆环中的任意一个圆环
- 扇区：构成磁盘上磁道的基本单位，是磁盘上数据读写的最小单位
- 寻道：把读写磁头移动到磁盘上适当的磁道上面的过程
- 旋转延时：在磁头定位后，指定扇区通过读写头所需要的时间。通常是磁盘旋转时间的一半

--------

### cache的基本原理

cache：高速缓存

- 直接映射：一种cache结构，其中每个存储器地址仅仅对应到cache中的一个位置
- 标记：表中的一个字段，包含了地址信息，这些地址信息可以用力啊判断cache中的字是否就是所请求的字
- 有效位：表中的一个字段，用来标识一个块是否含有一个有效的数据

#### cache访问

对每个可能的地址，在cache中进行如下查找：地址的低位用来找到cache中与该地址匹配的唯一项。具体可以分为：

- 标记域：用来与cache中标记域的值进行比较
- cache索引：用来选择块

![image-20211217151858765](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217151858765.png)

最低两位是字节偏移，先不管。低10位是索引，然后再用高20位的标记域来和cache中的标记比较并且cache是有效的，找到了就把cache中的数据取出，没找到就到内存中找。

由于cache不仅存储数据也存储标记位，cache所需要的总位数是cache大小和地址位数的函数。在前文中提及的块大小为一个字，但通常块为多字（块大小就是说这一行存储了多少的数据，上面的图存储了一个，一个数据就是一个字，32位），就像下面的情况：

- 32位地址
- 直接映射 cache
- cache 大小位 2^n 个块，因此 n 位被用来索引
- 块的大小为 2^m 个字 （2^m+2 字节)，因此 m 位用来查找块中的字，两位是字节偏移信息。

标记域的大小为:

```
 32 - (n + m + 2)
```

直接映射的 cache 总位数为：

```
2^n * (块大小 + 标记域大小 + 有效位域大小)
```

由于块大小为 2^m 个字 （2^m+5 位)，同时我们需要一位的有效位，因此一个这样的cache的位数是：

```
2^n * (2^m * 32 + (32 - n - m - 2) + 1)
= 2^n * (2^m * 32 + 31 - n - m)
```

![image-20211217154139598](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217154139598.png)![image-20211217154914237](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217154914237.png)

#### cache缺失处理

控制单元必然能够检测到缺失的发生，然后从主存（或者低一级的cache）中取回需要的数据来处理缺失。

cache缺失处理由两部分共同完成：处理器控制单元，以及一个进行初始化主存访问和重新填充cache的独立控制器。

cache缺失引起流水线阻塞，与中断不同，中断发生需要保存所有寄存器的状态。cache缺失时，我们等待主存操作完成时，整个处理器阻塞，临时寄存器和程序员可见的寄存器内容基本被冻结。

发生**指令cache缺失**的处理步骤：

1. 把程序计数器（PC）的原始值（当前PC - 4）送到存储器中
2. 通知主存执行一次读操作，并等待主存访问完成
3. 写cache项，将从主存取回的数据写入cache中存放数据的部分，并将地址的高位（从ALU中得到）写入标记域，设置有效位
4. 重启指令执行第一步，重新取指，这次该指令在cache中

数据访问时对cache的控制基本相同：缺失时，处理器阻塞，直到从存储器中取回数据后才响应。

#### 写操作处理

- 写直达：写操作总是同时更新cache和下一存储器层次，以保证二者一致性
- 写回：当发生写操作时，新的值仅仅被写入cache块中，只有当修改过的块被替换时才写到较低层次存储结构中
- 写缓冲：一个保存等待写入主存数据的缓冲队列

最简单的一种写入策略，叫作写直达（Write-Through）。在这个策略里，每一次数据都要写入到主内存里面。在写直达的策略里面，写入前，我们会先去判断数据是否已经在 Cache 里面了。如果数据已经在 Cache 里面了，我们先把数据写入更新到 Cache 里面，再写入到主内存里面；如果数据不在 Cache 里，我们就只更新主内存。

在 CPU Cache 的写入策略里，还有一种策略就叫作写回（Write-Back）。这个策略里，我们不再是每次都把数据写入到主内存，而是只写到 CPU Cache 里。只有当 CPU Cache 里面的数据要被“替换”的时候，我们才把数据写入到主内存里面去。

写回策略的过程是这样的：如果发现我们要写入的数据，就在 CPU Cache 里面，那么我们就只是更新 CPU Cache 里面的数据。同时，我们会标记 CPU Cache 里的这个 Block 是脏（Dirty）的。所谓脏的，就是指这个时候，我们的 CPU Cache 里面的这个 Block 的数据，和主内存是不一致的。如果我们发现，我们要写入的数据所对应的 Cache Block 里，放的是别的内存地址的数据，那么我们就要看一看，那个 Cache Block 里面的数据有没有被标记成脏的。如果是脏的话，我们要先把这个 Cache Block 里面的数据，写入到主内存里面。然后，再把当前要写入的数据，写入到 Cache 里，同时把 Cache Block 标记成脏的。如果 Block 里面的数据没有被标记成脏的，那么我们直接把数据写入到 Cache 里面，然后再把 Cache Block 标记成脏的就好了。

在用了写回这个策略之后，我们在加载内存数据到 Cache 里面的时候，也要多出一步同步脏 Cache 的动作。如果加载内存里面的数据到 Cache 的时候，发现 Cache Block 里面有脏标记，我们也要先把 Cache Block 里的数据写回到主内存，才能加载数据覆盖掉 Cache。

#### 一个cache的例子：内置FastMATH处理器

> 使用了分离的指令cache和数据cache

对于任何一个cache执行读请求的步骤：

1. 将地址送到适当的cache中，该地址来自程序计数器（指令访问）或ALU（数据访问）
2. 如果cache发出命中信号，请求的字就出现在数据线上。由于在请求的数据块中有16个字，因此需要选择正确的字。块索引域（上面提到的m）用来控制多路选择器，从检索到的块中选择16个字中的某个字
3. 如果cache发出缺失信号，我们把地址送到主存。当主存返回数据时，把它写入cache后再读出以满足请求。

![image-20211217163717730](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217163717730.png)

#### 小结

![image-20211217162455801](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217162455801.png)

--------

### cache性能的评估和改进

假定cache访问命中的开销时CPU正常执行周期的一部分：

```
CPU时间 = （CPU执行时钟周期数 + 存储器阻塞的时钟周期数） * 时钟周期
```

存储器阻塞的时钟周期数：

```
存储器阻塞的时钟周期数 = 读操作引起阻塞的时钟周期数 + 写操作引起阻塞的时钟周期数
```

```
读操作引起阻塞的时钟周期数 = （读的次数 / 程序数） * 读缺失率 * 读缺失代价
```

对于写直达机制，有两种情况引起阻塞：一种是写缺失，另一种是写缓冲区阻塞：

```
写操作引起阻塞的时钟周期数 = [(写的次数 / 程序数) * 写缺失率 * 写缺失代价] + 写缓冲区阻塞
```

在大部分直达cache结构中，读和写的缺失代价是一样的，如果假设写缓冲区阻塞可以被忽略，那么我们可以合并读写操作并共用一个缺失代价：

```
存储器阻塞的时钟周期数 = （存储器访问次数 / 程序数） * 缺失率 * 缺失代价
```

![image-20211217170634918](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217170634918.png)

CPI：平均每条指令执行需要的周期数

我们假设有 I 条指令，那么就有 I * 2% 次指令缺失，每次缺失代价为 100 个时钟周期，因此指令缺失时钟周期数就是 I * 2% * 100 = 2I。同理，得到 1.44I。不缺失的话，需要 I * CPI 个时钟周期，即 2I ，很容易理解。

平均存储器访问时间（AMAT）:

```
AMAT = 命中时间 + 缺失率 * 缺失代价
```

![image-20211217171736610](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217171736610.png)

#### 通过更灵活地放置块来减少cache缺失

前面我们讲的都是直接映射的方法。

另一种极端的方式是：一个块可以被放置在cache中的任何位置，这种机制称为**全相联**。因为存储器中的块可以与cache中任何一项相关，查找一个块需要检索cache中所有的项。为了使检索更有效，它是由一个与cache中每一个项都相关的比较器并行完成的。这些比较器加大了硬件开销。

介于直接映射和全相联之间的设计是**组相联**。在组相联cache中，每个块可被放置的位置数是固定的。每个块有n个位置可放的cache被称作n路组相联cache。一个n路组相联cache由很多组构成，每个组中有n块。

组相联映射将直接映射和全相联映射结合起来（就像跳表）：

- 一个块首先被直接映射到一个组，然后检索该组中所有的块判断是否匹配。

我们也能将这三种方式理解成哈希表的处理方式

#### 在cache中查找一个块

| 标记 | 索引 | 块偏移 |
| ---- | ---- | ------ |

1. 索引用来选择一个组
2. 标记位用来和选中组中的块进行比较来选择块（速度是最根本的，所以采用**并行比较**）
3. 块偏移是块中被请求数据的地址。

全相联没有索引，直接映射只需要一个比较器。四路组相联cache，需要4个比较器和一个4选1的多路选择器

![image-20211217190833625](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217190833625.png)

#### 替换块的选择

当直接映射的cache发生缺失时，被请求的块只能放置于cache中唯一位置，而原先占据那个位置的块必须被替换掉。在相联的cache中，被请求的块放置在什么位置需要进行选择，替换哪一块也要进行选择。

**LRU**（Least Recently Used：最近最少使用）算法

![image-20211217191435883](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217191435883.png)

#### 使用多级cache结构减少缺失代价

一级cache没有，就去访问二级cache，这比直接访问主存快得多。但是如果一级和二级都没有，就要访问主存，缺失代价也就更大。

一级cache更加致力于减少命中时间

二级叉车主要针对改善缺失率减小缺失代价

一个具体的例子：基数排序在数据量较大的时候，指令数小于快速排序，但是时钟周期数却和快排差不多，甚至还要多。就是cache捣的鬼：快排每项排序平均cache缺失数一直比基数排序少得多。

#### 通过分块进行软件优化

如果按行访问二维数组我们按行存储，利用局部性原理可以加快访问；如果按列访问我们就按列存储。

假定要处理多个数组，这些数组有些按行访问，有些按列访问，那么我们就使用分块算法对子矩阵进行操作。在数据被替换出去之前，最大限度的对已经装入cache的数据进行访问，即通过时间局部性的方法来降低cache缺失率。

```C
for (int i = 0; i < n; i++) {
	for (int j = 0; j < n; j++)
        A[i][j] = B[j][i];
}
```

上面这个程序A就是按行访问，B就是按列访问。

我们把这个矩阵拆成4个小矩阵来访问，就是分块技术。分块技术同时利用了空间局部性和时间局部性，对A利用了空间局部性，对B利用了时间局部性。

#### 小结

![image-20211217195908728](https://gitee.com/ceyewan/pic/raw/master/images/image-20211217195908728.png)

---------

